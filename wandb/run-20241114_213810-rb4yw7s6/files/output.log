
--- Pruning Level [1:0/35]: ---
classifier.0.weight  | nonzeros =  235200 /  235200 (100.00%) | total_pruned =       0 | shape = (300, 784)
classifier.0.bias    | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)
classifier.2.weight  | nonzeros =   30000 /   30000 (100.00%) | total_pruned =       0 | shape = (100, 300)
classifier.2.bias    | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)
classifier.4.weight  | nonzeros =    1000 /    1000 (100.00%) | total_pruned =       0 | shape = (10, 100)
classifier.4.bias    | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)
alive: 266610, pruned : 0, total: 266610, Compression rate :       1.00x  (  0.00% pruned)
Training Epochs:   0%|                                  | 0/100 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/u/antor/u12/alochab/cs578/Lottery-Ticket-Hypothesis-in-Pytorch/LTH.py", line 344, in <module>
    main(args, ITE=1)
  File "/u/antor/u12/alochab/cs578/Lottery-Ticket-Hypothesis-in-Pytorch/LTH.py", line 130, in main
    accuracy = test(model, test_loader, criterion)
  File "/u/antor/u12/alochab/cs578/Lottery-Ticket-Hypothesis-in-Pytorch/LTH.py", line 174, in test
    for data, target in test_loader:
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torchvision/datasets/mnist.py", line 146, in __getitem__
    img = self.transform(img)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 350, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
  File "/homes/alochab/myenv/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 922, in normalize
    if (std == 0).any():
KeyboardInterrupt
